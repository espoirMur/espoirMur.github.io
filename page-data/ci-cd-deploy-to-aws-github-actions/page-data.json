{"componentChunkName":"component---src-templates-blog-post-js","path":"/ci-cd-deploy-to-aws-github-actions/","result":{"data":{"site":{"siteMetadata":{"title":"My ideas' home"}},"markdownRemark":{"id":"ba9134fb-7847-5a53-aa3d-9a30aa575b80","excerpt":"Deploy a containerized python to AWS using Github Actions Recently at work we decided to build a CI/CD pipeline to deploy our application directly to AWS . I…","html":"<h2>Deploy a containerized python to AWS using Github Actions</h2>\n<p>Recently at work we decided to build a CI/CD pipeline to deploy our application directly to AWS . I had never worked with AWS and it was  the missing point on my cv to demonstrate that I have some devops skills . I decided to look for some tutorials online and I was not lucky to have what does what we need at work . I decided to write this guide by getting something working from various tutorials I found  online. </p>\n<h3>What you will learn from this tutorial</h3>\n<ul>\n<li>How to create an AWS architecture where you can deploy an python application</li>\n<li>How to use Github Actions to deploy to that architecture</li>\n<li>\n<p>Some gotcha about deploying on AWS and how I a managed to solve them. </p>\n<h3>Who is this tutorial for</h3>\n</li>\n</ul>\n<p>This tutorial is for middle level python developers who are familiar with docker and have a python application with docker-compose. </p>\n<h3>Which Application we will deploy</h3>\n<p>In this tutorial we will deploy a python application which has a celery worker, a celery scheduler and a redis database for task messaging and task queues. </p>\n<p>I am not planning to talk about celery and task queue and how to use those framework but you can get start with them <a href=\"https://medium.com/analytics-vidhya/python-celery-distributed-task-queue-demystified-for-beginners-to-professionals-part-1-b27030912fea\">here</a> and to get started with docker you can use <a href=\"https://samwalpole.com/getting-started-with-docker\">this one</a> and <a href=\"https://adamtheautomator.com/docker-compose-tutorial/\">this one</a> to be familiar with docker compose.</p>\n<p>I will not touch to any popular python web framework  such Django, Flask or FastAPi but you can adapt this tutorial to them and I am sure it will work like a charm.</p>\n<p>My friends who write Php , Javascrpit or any other fancy language can also leverage this tutorial and adapt something to their language.</p>\n<p>The application skeleton can be downloaded from <a href=\"https://github.com/espoirMur/deploy_python_to_aws_github_actions\">this link</a> to get start.</p>\n<h3>Getting started</h3>\n<p>To get start download a sample project we will be using by running the following command in your cmd, I hope you have git installed in your machine.</p>\n<p><code class=\"language-text\">git clone https://github.com/espoirMur/deploy_python_to_aws_github_actions.git</code></p>\n<p>As you can see this is just a dummy project which run with run 4 docker containers.</p>\n<p>You can follow the readme to get the project running for you.</p>\n<h3>Creating the AWS Architecture</h3>\n<p>Make sure you have created an AWS account and you have your credentials , the access key and the application secret.</p>\n<p>Most of the service used in this tutorial are available with an AWS free tier account. </p>\n<p>We will be using this tutorial and follow the steps they gave us to create the architecture we need :</p>\n<p>Basically those are the stack we need : </p>\n<p>\n    <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 590px;\">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 59.44055944055944%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAIAAADtbgqsAAAACXBIWXMAABYlAAAWJQFJUiTwAAAByUlEQVQoz21Ry27TUBDN1yLxFbCHBXTbDWIDK2DFBgmJUCmtcJPISZS6aRrn+v22Y9/X+MVchxaCah2N5o7vuXPmzIh6Bst8KAJ7szTmV/er6c3skhj6djXd6L9269ndQtuurve3OuZL7QKjyH2e+ywmI54FQjYgIQpjQmzHcXfm3vMD23Edx/Nc3/N8y7LDMEIQYgVBCLKW0ApajljiUMakEACyqUGhqWtQEQEqaQTnqgLQNqomBZNSiiob0diRULetqsu6Q8AQj8AH8BeSEdjgGBUkiCofyBK6rgPJo9txuv2ZKFwkd+PsfsIY7fr+kfwX/5LbrpO8TPSP4eWZ9e2F+/1lMDljxudDkfV9j7cfNKNoVMxPO/c9nqLlF3f86urds+v3z50fr8vN1yyNUfahKGxCHNtGD2lVwVOdq1T/EGnn0eRNNHkba+fU+BT6HqUUjd6bJjHNxWKBfOz//8woKN5puTVLrXlmzXMyxTiMJ4s8x4ZVWeLeLEJC30cTZFWcuF23/R80D0ld47tITOI4S1PUjypu1us8y4EecM8upVx9DK2lnD2CDSWMvCwPmIrhjjJP2TbI5qmnBuDsuI8ncbKk47YH8m98spyuaoA/zwAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"aws objects\" title=\"aws objects\" src=\"/static/164c090d70ce8655152a3cde434bb1f7/799d3/aws_objects.png\" srcset=\"/static/164c090d70ce8655152a3cde434bb1f7/00d96/aws_objects.png 148w,\n/static/164c090d70ce8655152a3cde434bb1f7/0b23c/aws_objects.png 295w,\n/static/164c090d70ce8655152a3cde434bb1f7/799d3/aws_objects.png 590w,\n/static/164c090d70ce8655152a3cde434bb1f7/2a3d6/aws_objects.png 885w,\n/static/164c090d70ce8655152a3cde434bb1f7/ae92f/aws_objects.png 1180w,\n/static/164c090d70ce8655152a3cde434bb1f7/4ee31/aws_objects.png 1430w\" sizes=\"(max-width: 590px) 100vw, 590px\" loading=\"lazy\">\n    </span>\n</p>\n <p>\n    <em><a href=\"https://chintugudiya.org/focus-areas/tech-work/overview-deploying-glific-on-aws-ecs-fargate-with-cd-in-place/\">\n    Source</a></em>\n</p>\n<p>We will deploy our application using the AWS ECS Fragate launch type which will pull docker images from the Elastic Container Registry aka ECR.</p>\n<h4>Why Fragate and not EC2?</h4>\n<p>AWS provide us basically two accounts launch type which are the Fragate Launch type and the EC2. </p>\n<p>Amazon Elastic Compute Cloud (Amazon EC2) provides scalable computing capacity in the Amazon Web Services (AWS) Cloud. Using Amazon EC2 eliminates your need to invest in hardware up front, so you can develop and deploy applications faster. You can use Amazon EC2 to launch as many or as few virtual servers as you need, configure security and networking, and manage storage. With EC2 you don’t need to care about hardware , everything hardware is managed by AWS. </p>\n<p>AWS Fargate is a technology that you can use with Amazon ECS to run <a href=\"https://aws.amazon.com/what-are-containers\">containers</a> without having to manage servers or clusters of Amazon EC2 instances.The  advantages Fragate over EC2 is the fact that you don’t have to configure, provision or scale clusters instance and care about virtual machine.</p>\n<p>In a nutshell : </p>\n<p>With a virtual machine, someone still has to manage the hardware, but with EC2 that someone is AWS and you never even see the hardware.</p>\n<p>With ECS on EC2, someone still has to manage the instances, but with ECS on Fargate that someone is AWS and you never even see the EC2 instances.</p>\n<p>ECS has a “launch type” of either EC2 (if you want to manage the instances yourself) or Fargate (if you want AWS to manage the instances). <a href=\"https://www.reddit.com/r/aws/comments/dvl601/eli5_aws_fargate/f7ddkup?utm_source=share&#x26;utm_medium=web2x&#x26;context=3\">Source</a>. </p>\n<p>Add cloud watch to check the logs\n<a href=\"https://aws.amazon.com/blogs/containers/create-a-ci-cd-pipeline-for-amazon-ecs-with-github-actions-and-aws-codebuild-tests/\">https://aws.amazon.com/blogs/containers/create-a-ci-cd-pipeline-for-amazon-ecs-with-github-actions-and-aws-codebuild-tests/</a></p>\n<h3>The objects we need :</h3>\n<p>To deploy the application we need the following objects : A cluster, a service , a task definition  with container definition, cloud watch for logging , iam roles.\nThe bellow picture show how those AWS objects interacts with each other.</p>\n<p>Let us define some of those objects and then we will investigate how to create a stack having them using the Python cdk . </p>\n<ul>\n<li><strong>A cluster</strong>: It is a logical group of container instances that ECS can use for deploying Docker containers. It provides compute power to run application container instances.  In practise a container is usually attached to an AWS Instance. </li>\n<li><strong>A service</strong>: It enables us to run and maintain a specified number of instances of a task definition simultaneously in an Amazon ECS cluster. ie. It helps us run single or multiple containers all using the same Task Definition.</li>\n<li><strong>The task definition</strong>: A task definition is a specification. You use it to define one or more containers (with image URIs) that you want to run together, along with other details such as environment variables, CPU/memory requirements, etc. The task definition doesn’t actually run anything, its a description of how things will be set up when something does run. The task definition is similar to the docker-compose file. We will later use the docker compose file to generate a task definition. </li>\n<li><strong>A task</strong> : A task is an actual thing that is running. ECS uses the task definition to run the task; it downloads the container images, configures the runtime environment based on other details in the task definition. You can run one or many tasks for any given task definition. Each running task is a set of one or more running containers - the containers in a task all run on the same instance.</li>\n<li><strong>cloudwatch</strong>: CloudWatch is a monitoring service , we are using it in this stack to get and visualize logs form the docker containers.</li>\n</ul>\n<p>With all the objects describes we can now move to how to create the object using the python cdk. </p>\n<h4>Creating the architecture:</h4>\n<p>This picture will be describing what we need to run the application: </p>\n<p>\n    <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 590px;\">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 70.74829931972789%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsSAAALEgHS3X78AAACXElEQVQ4y31T227UMBDd//8FXvkC3uEBJF6QSgtF6m6bbC6b+9VJHOd+OPaS0hYJS9Z4JuPjM3Mmh23bsK4rtN2XPht/t8+xFf9bOuewg2n77eYWcZJCDQOUUq/3MGKYF1SxjzyJUVY1yrJCUZTIi4J+hXEc/wIuy4LvP+5R1cKAa3/We56x0J+kMHnRzSecPn/Aoxvg4XiE6/kkkSCKYnRd9xrwbcmG+TKbWPrxHcov7yG6Ht7dV/ghQeKEIBITmQVhhLZtXwPq0l6C7XtZVpxtG47jIGOJke8hD1xYlg0/CNEQ6Oy4/wLq8vRa//R0L31d+dg0Q04LGlHD5mXfsY11XA8ut2U7kLLH4aW6+oPDJN3smr2shYBoGgjRoGDMuiRwoxRJVpi4PrtRhigrzR2lhivDln3o6QRhgDRP0A89BZmprILsOwzjQGFmFFTSC2PUZDIy9nB6hOP7KOlL1WNg/mHgONhnB3leQI0EnhqWJw1j1fewzi4qPRLTZGJa+X7SrdkwMbaxHXKcMc4TSfUacMD9/S80akRNBYeJjNWMh0uFslU4hQJR2cGKBbysRVz15pzWEsdAoOoGk6PVV6zs0HJ2LkFEBjM6KcmAM0dxzn6ISrQI4hR5KVCyp14Qs3ctLM5gxb7atLpd7iViTnUt+aoiFdWlKGlK0bHTk8VHRvbpycxbmuV44phIPnpkTNvbu59oKE7Gb0VZmp4fngfYiNOiowid7PjHVMYWVUk2NRWv+YvlJtbKFk3XUO2UjIUpVfsGcJ+3HVSz21k/s3+Rc/2+mv32zrZu+A2qPjMTo/STDQAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"aws architecture\" title=\"aws architecture\" src=\"/static/416046a7ad233f3cdd57171f273a55c2/799d3/aws_architecture.png\" srcset=\"/static/416046a7ad233f3cdd57171f273a55c2/00d96/aws_architecture.png 148w,\n/static/416046a7ad233f3cdd57171f273a55c2/0b23c/aws_architecture.png 295w,\n/static/416046a7ad233f3cdd57171f273a55c2/799d3/aws_architecture.png 590w,\n/static/416046a7ad233f3cdd57171f273a55c2/2a3d6/aws_architecture.png 885w,\n/static/416046a7ad233f3cdd57171f273a55c2/ae92f/aws_architecture.png 1180w,\n/static/416046a7ad233f3cdd57171f273a55c2/400d5/aws_architecture.png 1764w\" sizes=\"(max-width: 590px) 100vw, 590px\" loading=\"lazy\">\n    </span>\n</p>\n <p>\n    <em>Our architecture and workflow in  a nutshell <em>\n</em></em></p>\n<p>To build the infrastructure, we will be leverage the <a href=\"https://aws.amazon.com/cdk/\">AWS Cloud Development Kit (CDK)</a>. If you are new to the CDK, see <a href=\"https://docs.aws.amazon.com/cdk/latest/guide/getting_started.html\">Getting Started with the AWS CDK</a>, it is  a simple and straigthforward to install. In this post, we will be using the CDK with Python 3.7.\nAnother alternative to the cdk is to create the application via the aws console, however I found the cdk to be simplest approach because , I am a programmer and with the code we can have a full control on what we are creating .</p>\n<p>After installing the cdk check if it working with the following command: </p>\n<ul>\n<li><code class=\"language-text\">cdk --version</code> it should put the your cdk version.</li>\n</ul>\n<h5>Initializing the AWS  CLI :</h5>\n<p>Make sure you have the aws cli installed in your computer. . <a href=\"https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.html\">Configure your AWS CLI</a> with an IAM user that has permissions to create the resources (VPC, ECS, ECR, IAM Role) described in the template below.\nAfter the configuration you should have the aws keys stored in your computer at the following location : </p>\n<ul>\n<li><code class=\"language-text\">~/.aws/credentials</code> : if you are using a mac or linux</li>\n<li><code class=\"language-text\">C:\\Users\\`USERNAME`\\.aws\\config</code>: if you are on Windows </li>\n</ul>\n<p>The content of that file should look like this one: </p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">[default]\nregion=your region\naws_access_key_id = *********************************\naws_secret_access_key = ******************************</code></pre></div>\n<p>We the crendentials , the cli and the cdk installed let us move to the second step about creating the archictecture. </p>\n<h4>Initializing The cdk Project :</h4>\n<p>To initialize the cdk we will create another project wich will contains the code to create the architecture.</p>\n<p><em><em>Step 1</em></em> : Creating the project </p>\n<p>Run the following command to creat a new cdk project :\n<code class=\"language-text\">mkdir ecs-devops-cdk</code></p>\n<p>Enter the project using :\n<code class=\"language-text\">cd ecs-devops-cdk</code></p>\n<p>Or if you are using Vscode you can open the project with vs code using :\n<code class=\"language-text\">code ecs-devops-cdk</code></p>\n<ul>\n<li><em>Step 2</em>:  Initialize the python cdk project : </li>\n</ul>\n<p>To initialize the cdk project run the following command :\n<code class=\"language-text\">cdk init --language python</code></p>\n<p>The command will create a new python cdk project and we will be editing it in the next step to build our stack. </p>\n<p>After a quick look you should see a structure like this in your project: </p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">.\n├── README.md\n├── app.py\n├── cdk.json\n├── ecs_devops_cdk\n│   ├── __init__.py\n│   └── ecs_devops_cdk_stack.py\n├── requirements.txt\n├── setup.py\n└── source.bat</code></pre></div>\n<ul>\n<li><strong>Step 3</strong> : activate virtual enviroment : </li>\n</ul>\n<p>You can activate your virtuall environment using the following code : </p>\n<p>On mac and linux : <code class=\"language-text\">source .env/bin/activate</code>\nFor windows : <code class=\"language-text\">.env\\Scripts\\activate.bat</code></p>\n<ul>\n<li><strong>step 4</strong> : Installing dependencies:\nWith the virtual environment created we can now install the dependencies : </li>\n</ul>\n<p><code class=\"language-text\">pip install -r requirements.txt</code>\nand\n<code class=\"language-text\">pip install aws_cdk.aws_ec2 aws_cdk.aws_ecs aws_cdk.aws_ecr aws_cdk.aws_iam</code></p>\n<p>With the project initialized we can now move to the next step where we will be creating our components. </p>\n<h4>Creating the objects :</h4>\n<p>We can now move to the stack creation step </p>\n<p>If you open the file under <code class=\"language-text\">ecs_devops_cdk/ecs_devops_cdk_stack.py</code>  you should be able to see the followings : </p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">from aws_cdk import core\nclass  EcsDevopsCdkStack(core.Stack):\n\n  \n\ndef  __init__(self, scope: core.Construct, construct_id:  str,  **kwargs)  -&gt;  None:\n\nsuper().__init__(scope, construct_id,  **kwargs)</code></pre></div>\n<p>it is basically a class that will contains the code defining our stack. </p>\n<h5>Import the core functionality :</h5>\n<p>Edit the first line to import the code we need to create the following stack: </p>\n<p><code class=\"language-text\">from aws_cdk import  (core, aws_ecs as ecs, aws_ecr as ecr, aws_ec2 as ec2, aws_iam as iam, aws_logs)</code></p>\n<h5>Create the container repository</h5>\n<p>To create a container repository you can use the following command : </p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">ecr_repository = ecr.Repository(self,  &quot;ecs-devops-repository&quot;, repository_name=&quot;ecs-devops-repository&quot;)</code></pre></div>\n<h5>Creating the VPC</h5>\n<p>We can either create a vpc or use an existing vpc .\nTo create a vpc use can add the following code the  <code class=\"language-text\">__init__</code> method. </p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">vpc = ec2.Vpc(self,  &quot;ecs-devops-vpc&quot;, max_azs=3)</code></pre></div>\n<p>You can also use an existing vpc , if that is the case for you use the following lines: </p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">vpc = ec2.Vpc.from_lookup(self, &quot;ecs-devops-vpc&quot;,vpc_id=&#39;vpc-number&#39;)</code></pre></div>\n<p>For this you need the vpc name and the corresponding id. </p>\n<h5>Cluster Creation :</h5>\n<p>With the vpc created we can attached the cluster to it .\nTo create the cluster we can use the following code : </p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">cluster = ecs.Cluster(self,  \n\t\t\t\t\t  &quot;ecs-devops-cluster&quot;, \n\t\t\t\t\t  cluster_name=&quot;ecs-devops-cluster&quot;,\n\t\t\t\t\t  vpc=vpc)</code></pre></div>\n<h5>Creating the Role:</h5>\n<p>Let us create the role , the role will give the service the permission to do some tasks . </p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">execution_role = iam.Role(self,  &quot;ecs-devops-execution-role&quot;, assumed_by=iam.ServicePrincipal(&quot;ecs-tasks.amazonaws.com&quot;), role_name=&quot;ecs-devops-execution-role&quot;)</code></pre></div>\n<p>With the execution role created we can it to policy to give it the permission it needs (This sentence needs to be refractored)</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">execution_role.add_to_policy(iam.PolicyStatement( effect=iam.Effect.ALLOW, resources=[&quot;*&quot;], actions=[  &quot;ecr:GetAuthorizationToken&quot;,  &quot;ecr:BatchCheckLayerAvailability&quot;,  &quot;ecr:GetDownloadUrlForLayer&quot;,  &quot;ecr:BatchGetImage&quot;,  &quot;logs:CreateLogStream&quot;,  &quot;logs:PutLogEvents&quot;  ]  ))</code></pre></div>\n<p>With the iam role create we can attach to it a task definition</p>\n<h5>Creating the task definition :</h5>\n<p>Here is the code we used to create the task definition ; </p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">task_definition = ecs.FargateTaskDefinition(self,  &quot;ecs-devops-task-definition&quot;, execution_role=execution_role, family=&quot;ecs-devops-task-definition&quot;)</code></pre></div>\n<p>And  the container : </p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">container = task_definition.add_container(&quot;ecs-devops-sandbox&quot;, image=ecs.ContainerImage.from_registry(&quot;amazon/amazon-ecs-sample&quot;)  )</code></pre></div>\n<p>In the code above, we are initially specifying the Task Definition to run with an example container from a public AWS sample registry. This sample container is replaced with our application container when our CI/CD pipeline updates the Task Definition. We are using the container from the sample registry to allow the Service to stabilize before any application container images are added to our ECR repository.</p>\n<p>With the task definition created we can attach a service that will be running it  . </p>\n<h5>Creating the service :</h5>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">service = ecs.FargateService(self,  &quot;ecs-devops-service&quot;, cluster=cluster, task_definition=task_definition, service_name=&quot;ecs-devops-service&quot;)</code></pre></div>\n<p>The service use the task definition and you can see it is attached to our created cluster. </p>\n<h5>Creating the cloudwatch service :</h5>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">log_group = aws_logs.LogGroup(\n\nself,\n\n&quot;ecs-devops-service-logs-groups&quot;,\n\nlog_group_name=&quot;ecs-devops-service-logs&quot;)</code></pre></div>\n<p>As stated before we will be transferring the docker logs to our log group created in cloudwatch.</p>\n<p>With all the objects created let us make sure that we have all the ingredients for our stack in the following updated file . </p>\n<p><code class=\"language-text\">ecs_devops_cdk/ecs_devops_cdk_stack.py</code></p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">from aws_cdk import  (core, aws_ecs as ecs, aws_ecr as ecr, aws_ec2 as ec2, aws_iam as iam, aws_logs)\n\n  \n  \n\nclass  EcsDevopsCdkStack(core.Stack):\n\n  \n\ndef  __init__(self, scope: core.Construct, construct_id:  str,  **kwargs)  -&gt;  None:\n\nsuper().__init__(scope, construct_id,  **kwargs)\n\n  \n\n# The code that defines your stack goes here\n\n  \n\necr_repository = ecr.Repository(self,\n\n&quot;ecs-devops-repository&quot;,\n\nrepository_name=&quot;ecs-devops-repository&quot;)\n\n  \n  \n\nvpc = ec2.Vpc(self,  &quot;ecs-devops-vpc&quot;,  max_azs=3)\n\n  \n\ncluster = ecs.Cluster(self,\n\n&quot;ecs-devops-cluster&quot;,\n\ncluster_name=&quot;ecs-devops-cluster&quot;,\n\nvpc=vpc)\n\nexecution_role = iam.Role(self,\n\n&quot;ecs-devops-execution-role&quot;,\n\nassumed_by=iam.ServicePrincipal(&quot;ecs-tasks.amazonaws.com&quot;),\n\nrole_name=&quot;ecs-devops-execution-role&quot;)\n\n  \n\nexecution_role.add_to_policy(iam.PolicyStatement(  effect=iam.Effect.ALLOW,\n\nresources=[&quot;*&quot;],\n\nactions=[&quot;ecr:GetAuthorizationToken&quot;,\n\n&quot;ecr:BatchCheckLayerAvailability&quot;,\n\n&quot;ecr:GetDownloadUrlForLayer&quot;,\n\n&quot;ecr:BatchGetImage&quot;,\n\n&quot;logs:CreateLogStream&quot;,\n\n&quot;logs:PutLogEvents&quot;  ]  ))\n\ntask_definition = ecs.FargateTaskDefinition(self,\n\n&quot;ecs-devops-task-definition&quot;,\n\nexecution_role=execution_role,\n\nfamily=&quot;ecs-devops-task-definition&quot;)\n\ncontainer = task_definition.add_container(&quot;ecs-devops-sandbox&quot;,\n\nimage=ecs.ContainerImage.from_registry(&quot;amazon/amazon-ecs-sample&quot;))\n\nservice = ecs.FargateService(self,\n\n&quot;ecs-devops-service&quot;,\n\ncluster=cluster,\n\ntask_definition=task_definition,\n\nservice_name=&quot;ecs-devops-service&quot;)\n\nlog_group = aws_logs.LogGroup(self,\n\n&quot;ecs-devops-service-logs-groups&quot;,\n\nlog_group_name=&quot;ecs-devops-service-logs&quot;)</code></pre></div>\n<p>Before creating the stack  open the file <code class=\"language-text\">app.py</code> </p>\n<p>You should see something like this : </p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">from aws_cdk import core\n\n  \n\nfrom ecs_devops_cdk.ecs_devops_cdk_stack import EcsDevopsCdkStack\n\n  \n  \n\napp = core.App()\n\nEcsDevopsCdkStack(app,  &quot;ecs-devops-cdk&quot;)\n\n  \n\napp.synth()</code></pre></div>\n<p>Replace the line where your stack is instanciate 4th line with the following : </p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">EcsDevopsCdkStack(app,  &quot;ecs-devops-cdk&quot;,  env={\n\n&#39;account&#39;:  &quot;**************&quot;,\n\n&#39;region&#39;:  &quot;your region&quot;\n\n})</code></pre></div>\n<p>With this set you can now create your stack\nWith the code created we can now run the following command to create our stack.</p>\n<p><code class=\"language-text\">cdk deploy</code></p>\n<p>If everything goes well you should have your stack created . As a results you will have a cluster , running a service that deploys a task definition , and a Cloudwatch log group create . </p>\n<p>You can check your stack from the AWS console by navigating to the following <a href=\"https://us-east-2.console.aws.amazon.com/cloudformation/home?region=us-east-2#/stacks?filteringStatus=active&#x26;filteringText=&#x26;viewNested=true&#x26;hideStacks=false\">link</a>.</p>\n<p>You should be able to see something like this : </p>\n<p>Put the screenshot here</p>\n<p>If you want you can check this project on github <a href=\"https://github.com/espoirMur/ecs-devops-cdk\">here</a>\nWith the task created we can now move back to the project and see how to deploy it .</p>\n<h3>Setup Github Actions</h3>\n<p>(Should probably talk about what is ci/cd and what are github actions)\nIn this section we will setup Github Actions  that will automatically deploy the code to the AWS stack we have just created. </p>\n<p>The action on every push to the master branch will build  a docker image for our application, login to ECR , push the image to the ECR , update the task definition with the new image pushed url , and start the service with the associated task definition in the AWS Cluster.</p>\n<p>(Put an image here)</p>\n<p>Here are a list of the github actions we will be using : </p>\n<ul>\n<li><a href=\"http://github.com/aws-actions/configure-aws-credentials\">Configure-aws-credentials</a> –This will help to  configure AWS credential and region environment variables for use in other GitHub Actions. </li>\n<li><a href=\"http://github.com/aws-actions/amazon-ecr-login\">Amazon-ecr-login</a> – This will enable us to log in the local Docker client to one or more Amazon Elastic Container Registry (ECR) registries. After logging we can therefore push our docker images to the registry. </li>\n<li><a href=\"http://github.com/aws-actions/amazon-ecs-render-task-definition\">Amazon ECS-render-task-definition</a> – This will help us to render the docker image uri to the task definition.</li>\n<li><a href=\"http://github.com/aws-actions/amazon-ecs-deploy-task-definition\">Amazon ECS-deploy-task-definition</a> – This is the action that does the real deploy for us. It will register the AWS task definition to ECS and then deploys it to an Amazon ECS service.</li>\n<li><a href=\"https://github.com/docker/setup-buildx-action\">Docker Buildx</a>: This actions will help us to setup the most recent version of docker build , buildx which support caching. It is not mandotory if you don’t need to use caching you can skip it . </li>\n</ul>\n<h4>Back To the Business : The code we want to deploy .</h4>\n<p>Let go back to the project I introduced in the beginning and we will work from it.\nFrom your command line move to the project directory : </p>\n<p><code class=\"language-text\">cd deploy_python_to_aws_github_actions</code></p>\n<p>Activate your virtual enviroment with : </p>\n<p><code class=\"language-text\">source .venv/bin/activate</code></p>\n<h4>Creating the task-definition:</h4>\n<p>Let recall what is the a task definition it just  a specification. You use it to define one or more containers (with image URIs) that you want to run together, along with other details such as environment variables, CPU/memory requirements, etc.\nSince the task definition role is similar to a docker-compose file role , we will therefore use the docker-compose file to generate the task-defintion. We will leverage a python tool called <a href=\"https://github.com/micahhausler/container-transform\">container-transform</a> to accomplish that actions.</p>\n<p>You can install it in your project virtual environment with : </p>\n<p><code class=\"language-text\">pip install container-transform</code></p>\n<p>With the tool installed we can now use to generate the task definition.</p>\n<p><code class=\"language-text\">cat docker-compose.yml | container-transform  -v &gt; .aws/task-definition.json</code></p>\n<p>The output of this command is send to the file <code class=\"language-text\">.aws/task-definition.json</code> , if everything went well you can have something like this : </p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">{\n\n&quot;requiresCompatibilities&quot;:  [\n\n&quot;FARGATE&quot;\n\n],\n\n&quot;inferenceAccelerators&quot;:  [],\n\n&quot;containerDefinitions&quot;:  [{\n\n&quot;command&quot;:  [&quot;celery&quot;,  &quot;-A&quot;,  &quot;celery_factory:celery&quot;,  &quot;beat&quot;,  &quot;--scheduler=redbeat.RedBeatScheduler&quot;,  &quot;--loglevel=debug&quot;],\n\n&quot;essential&quot;:  true,\n\n&quot;image&quot;:  &quot;spiny-pi-cards-aws:00000&quot;,\n\n&quot;logConfiguration&quot;:  {\n\n&quot;logDriver&quot;:  &quot;awslogs&quot;,\n\n&quot;options&quot;:  {\n\n&quot;awslogs-group&quot;:  &quot;spiny-pi-cards-logs&quot;,\n\n&quot;awslogs-region&quot;:  &quot;us-east-2&quot;,\n\n&quot;awslogs-stream-prefix&quot;:  &quot;celery-beat&quot;\n\n}\n\n},\n\n&quot;name&quot;:  &quot;celery-beat&quot;,\n\n&quot;stopTimeout&quot;:  120\n\n},\n\n{\n\n&quot;command&quot;:  [&quot;celery&quot;,  &quot;-A&quot;,  &quot;celery_factory:celery&quot;,  &quot;worker&quot;,  &quot;--loglevel=error&quot;,  &quot;-E&quot;],\n\n&quot;essential&quot;:  true,\n\n&quot;image&quot;:  &quot;spiny-pi-cards-aws:00000&quot;,\n\n&quot;logConfiguration&quot;:  {\n\n&quot;logDriver&quot;:  &quot;awslogs&quot;,\n\n&quot;options&quot;:  {\n\n&quot;awslogs-group&quot;:  &quot;spiny-pi-cards-logs&quot;,\n\n&quot;awslogs-region&quot;:  &quot;us-east-2&quot;,\n\n&quot;awslogs-stream-prefix&quot;:  &quot;celery-worker&quot;\n\n}\n\n},\n\n&quot;name&quot;:  &quot;celery-worker&quot;,\n\n&quot;startTimeout&quot;:  10,\n\n&quot;stopTimeout&quot;:  120\n\n},\n\n{\n\n&quot;command&quot;:  [\n\n&quot;celery&quot;,\n\n&quot;-A&quot;,\n\n&quot;celery_factory:celery&quot;,\n\n&quot;flower&quot;,\n\n&quot;--loglevel=error&quot;,\n\n&quot;-E&quot;\n\n],\n\n&quot;environment&quot;:  [\n\n{\n\n&quot;name&quot;:  &quot;FLOWER_PORT&quot;,\n\n&quot;value&quot;:  &quot;5556&quot;\n\n}\n\n],\n\n&quot;essential&quot;:  true,\n\n&quot;image&quot;:  &quot;spiny-pi-cards-aws:00000&quot;,\n\n&quot;logConfiguration&quot;:  {\n\n&quot;logDriver&quot;:  &quot;awslogs&quot;,\n\n&quot;options&quot;:  {\n\n&quot;awslogs-group&quot;:  &quot;spiny-pi-cards-logs&quot;,\n\n&quot;awslogs-region&quot;:  &quot;us-east-2&quot;,\n\n&quot;awslogs-stream-prefix&quot;:  &quot;celery-flower&quot;\n\n}\n\n},\n\n&quot;name&quot;:  &quot;flower&quot;,\n\n&quot;portMappings&quot;:  [\n\n{\n\n&quot;containerPort&quot;:  5556,\n\n&quot;hostPort&quot;:  5556\n\n}\n\n],\n\n&quot;startTimeout&quot;:  30,\n\n&quot;stopTimeout&quot;:  120\n\n},\n\n{\n\n&quot;essential&quot;:  true,\n\n&quot;image&quot;:  &quot;redis&quot;,\n\n&quot;name&quot;:  &quot;redis&quot;,\n\n&quot;logConfiguration&quot;:  {\n\n&quot;logDriver&quot;:  &quot;awslogs&quot;,\n\n&quot;options&quot;:  {\n\n&quot;awslogs-group&quot;:  &quot;spiny-pi-cards-logs&quot;,\n\n&quot;awslogs-region&quot;:  &quot;us-east-2&quot;,\n\n&quot;awslogs-stream-prefix&quot;:  &quot;redis-database&quot;\n\n}\n\n},\n\n&quot;startTimeout&quot;:  5,\n\n&quot;stopTimeout&quot;:  120,\n\n&quot;portMappings&quot;:  [\n\n{\n\n&quot;containerPort&quot;:  6379\n\n}\n\n]\n\n}\n\n],\n\n&quot;volumes&quot;:  [],\n\n&quot;networkMode&quot;:  &quot;awsvpc&quot;,\n\n&quot;memory&quot;:  &quot;6144&quot;,\n\n&quot;cpu&quot;:  &quot;2048&quot;,\n\n&quot;executionRoleArn&quot;:  &quot;arn:aws:iam::969273490168:role/spiny_pi_cards-execution-role&quot;,\n\n&quot;family&quot;:  &quot;spiny_pi_cards-task-definition&quot;,\n\n&quot;taskRoleArn&quot;:  &quot;&quot;,\n\n&quot;placementConstraints&quot;:  []\n\n}</code></pre></div>\n<p>What to note here , it all the services we have in the docker-compose file are now in the <code class=\"language-text\">containerDefinitions</code> sections of our task definition.\nHowever that file is not yet full completed we will have to update it with other keys such as the network mode, the resources, the execution role we created before, and the logging option for sending logs to Cloudwatch. Let go now and edit the file by adding the following. And we also need to remove the <code class=\"language-text\">link</code> key from each container definition. </p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">&quot;requiresCompatibilities&quot;:  [\n\n&quot;FARGATE&quot;\n\n],\n\n&quot;inferenceAccelerators&quot;:  [],\n&quot;volumes&quot;:  [],\n\n&quot;networkMode&quot;:  &quot;awsvpc&quot;,\n\n&quot;memory&quot;:  &quot;512&quot;,\n\n&quot;cpu&quot;:  &quot;256&quot;,\n\n&quot;executionRoleArn&quot;:  &quot;arn:aws:iam::Your-id-from-aws:role/ecs-devops-execution-role&quot;,\n\n&quot;family&quot;:  &quot;ecs-devops-task-definition&quot;,\n\n&quot;taskRoleArn&quot;:  &quot;&quot;,\n\n&quot;placementConstraints&quot;:  []</code></pre></div>\n<p>What are those elements ? </p>\n<ul>\n<li><code class=\"language-text\">requiresCompatibilities</code> : Here we are just specifying that our launch type is of Fragate type . </li>\n<li><code class=\"language-text\">networkMode</code> : This is the Docker networking mode to use for the containers in the task. AWS offer the following network modes : <code class=\"language-text\">none</code>, <code class=\"language-text\">bridge</code>, <code class=\"language-text\">awsvpc</code>, and <code class=\"language-text\">host</code>. In Fragate launch type the <code class=\"language-text\">awsvpc</code> network mode is required.  With this setting the task is allocated its own elastic network interface (ENI) and a primary private IPv4 address. This gives the task the same networking properties as Amazon EC2 instances. (Put what I mean by this here) Learn more about the networking mode <a href=\"https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-networking.html\">here</a> . </li>\n<li><code class=\"language-text\">memory</code>: is the amount of ram to allocate to the containners, if your cluster does not have any registered container instances with the requested memory available, the task will fail.</li>\n<li><code class=\"language-text\">cpu</code>: The number of <code class=\"language-text\">cpu</code> units the Amazon ECS container agent will reserve for the container. </li>\n<li><code class=\"language-text\">executionRoleArn</code>: The Amazon Resource Name (ARN) of the task execution role that grants the Amazon ECS container agent permission to make AWS API calls on your behalf. As you can see it is the iam role  we created in our cloudformation stack.</li>\n<li><code class=\"language-text\">family</code>: is the name of the task definition we created on the cloud formation stack.</li>\n</ul>\n<p>In each container definition we need to add the code to send the container logs to cloudwatch.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">&quot;logConfiguration&quot;:  {\n\n&quot;logDriver&quot;:  &quot;awslogs&quot;,\n\n&quot;options&quot;:  {\n\n&quot;awslogs-group&quot;:  &quot;ecs-devops-service-logs-groups&quot;,\n\n&quot;awslogs-region&quot;:  &quot;us-east-2&quot;,\n\n&quot;awslogs-stream-prefix&quot;:  &quot;celery-beat&quot;\n\n}\n\n},</code></pre></div>\n<p>Add those line to each aws service and just change the <code class=\"language-text\">awslogs-stream-prefix</code> key and put the containner name.\nTo learn more about task-definitions parameters you can check <a href=\"https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition_parameters.html\">the aws documentation</a></p>\n<p>With those parameters edited we end up with the following task-definition. </p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">{\n\n&quot;containerDefinitions&quot;:  [\n\n{\n\n&quot;command&quot;:  [\n\n&quot;celery&quot;,\n\n&quot;-A&quot;,\n\n&quot;celery_factory:celery&quot;,\n\n&quot;beat&quot;,\n\n&quot;--scheduler=redbeat.RedBeatScheduler&quot;,\n\n&quot;--loglevel=debug&quot;\n\n],\n\n&quot;essential&quot;:  true,\n\n&quot;image&quot;:  &quot;task_runner&quot;,\n\n&quot;links&quot;:  [&quot;redis&quot;],\n\n&quot;name&quot;:  &quot;celery-beat&quot;,\n\n&quot;logConfiguration&quot;:  {\n\n&quot;logDriver&quot;:  &quot;awslogs&quot;,\n\n  \n\n&quot;options&quot;:  {\n\n&quot;awslogs-group&quot;:  &quot;ecs-devops-service-logs-groups&quot;,\n\n  \n\n&quot;awslogs-region&quot;:  &quot;us-east-2&quot;,\n\n  \n\n&quot;awslogs-stream-prefix&quot;:  &quot;celery-beat&quot;\n\n}\n\n}\n\n},\n\n{\n\n&quot;command&quot;:  [\n\n&quot;celery&quot;,\n\n&quot;-A&quot;,\n\n&quot;celery_factory:celery&quot;,\n\n&quot;worker&quot;,\n\n&quot;--loglevel=error&quot;,\n\n&quot;-E&quot;\n\n],\n\n&quot;essential&quot;:  true,\n\n&quot;image&quot;:  &quot;task_runner&quot;,\n\n&quot;links&quot;:  [&quot;redis&quot;],\n\n&quot;name&quot;:  &quot;celery-worker&quot;,\n\n&quot;logConfiguration&quot;:  {\n\n&quot;logDriver&quot;:  &quot;awslogs&quot;,\n\n  \n\n&quot;options&quot;:  {\n\n&quot;awslogs-group&quot;:  &quot;ecs-devops-service-logs-groups&quot;,\n\n  \n\n&quot;awslogs-region&quot;:  &quot;us-east-2&quot;,\n\n  \n\n&quot;awslogs-stream-prefix&quot;:  &quot;celery-worker&quot;\n\n}\n\n}\n\n},\n\n{\n\n&quot;command&quot;:  [&quot;./start_flower&quot;],\n\n&quot;environment&quot;:  [\n\n{\n\n&quot;name&quot;:  &quot;FLOWER_PORT&quot;,\n\n&quot;value&quot;:  &quot;5556&quot;\n\n}\n\n],\n\n&quot;essential&quot;:  true,\n\n&quot;image&quot;:  &quot;task_runner&quot;,\n\n&quot;logConfiguration&quot;:  {\n\n&quot;logDriver&quot;:  &quot;awslogs&quot;,\n\n  \n\n&quot;options&quot;:  {\n\n&quot;awslogs-group&quot;:  &quot;ecs-devops-service-logs-groups&quot;,\n\n  \n\n&quot;awslogs-region&quot;:  &quot;us-east-2&quot;,\n\n  \n\n&quot;awslogs-stream-prefix&quot;:  &quot;celery-flower&quot;\n\n}\n\n},\n\n&quot;links&quot;:  [&quot;redis&quot;],\n\n&quot;name&quot;:  &quot;flower&quot;,\n\n&quot;portMappings&quot;:  [\n\n{\n\n&quot;containerPort&quot;:  5556,\n\n&quot;hostPort&quot;:  5556\n\n}\n\n]\n\n},\n\n{\n\n&quot;essential&quot;:  true,\n\n&quot;image&quot;:  &quot;redis&quot;,\n\n&quot;name&quot;:  &quot;redis&quot;,\n\n&quot;containerPort&quot;:  6379,\n\n&quot;logConfiguration&quot;:  {\n\n&quot;logDriver&quot;:  &quot;awslogs&quot;,\n\n&quot;options&quot;:  {\n\n&quot;awslogs-group&quot;:  &quot;ecs-devops-service-logs-groups&quot;,\n\n  \n\n&quot;awslogs-region&quot;:  &quot;us-east-2&quot;,\n\n  \n\n&quot;awslogs-stream-prefix&quot;:  &quot;celery-redis&quot;\n\n}\n\n}\n\n}\n\n],\n\n&quot;requiresCompatibilities&quot;:  [&quot;FARGATE&quot;],\n\n  \n\n&quot;inferenceAccelerators&quot;:  [],\n\n&quot;volumes&quot;:  [],\n\n&quot;networkMode&quot;:  &quot;awsvpc&quot;,\n\n&quot;memory&quot;:  &quot;512&quot;,\n\n&quot;cpu&quot;:  &quot;256&quot;,\n\n&quot;executionRoleArn&quot;:  &quot;arn:aws:iam::Your-id-from-aws:role/ecs-devops-execution-role&quot;,\n\n&quot;family&quot;:  &quot;ecs-devops-task-definition&quot;,\n\n&quot;taskRoleArn&quot;:  &quot;&quot;,\n\n&quot;placementConstraints&quot;:  []\n\n}</code></pre></div>\n<p>With the task definition in place , let us move to the Github Actions: </p>\n<h4>Creating the Github actions:</h4>\n<p>To create Github Actions we can add them from the Github ui or do it from command line.\nTo peform that operation via commad line you neet to have a folder called <code class=\"language-text\">.github/workflows</code> in your project directory and add your action <code class=\"language-text\">.yml</code> file within it.</p>\n<p>Let us create the folder:\n<code class=\"language-text\">mkdir .github &amp;&amp; mkdir .github/workflows</code></p>\n<p>Then we can create our action file with <code class=\"language-text\">touch .github/workflows/deploy_aws.yml</code></p>\n<h5>Setting up</h5>\n<p>In the deploy to aws action we add the following code  : </p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">on:\n\npush:\n\nbranches:\n\n-  master\n\nname:  Deploy to Amazon ECS</code></pre></div>\n<p>In this line we are only specifying the event that will trigger our action, this action will be trriggered on a push to master.</p>\n<p>Next let us specify the set of job that our actions will run: </p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">jobs:\n\ndeploy:\n\nname:  Deploy\n\nruns-on:  ubuntu-latest</code></pre></div>\n<p>This tell our job to run on ubuntu instance .\nThe job have the following steps </p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">steps:\n\n-  name:  Checkout\n\nuses:  actions/checkout@v1</code></pre></div>\n<p>This action checks-out your repository under <code class=\"language-text\">$GITHUB_WORKSPACE</code>, so your workflow can access it.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">-  name:  Set up Python python-version\n\nuses:  actions/setup-python@v1\n\nwith:\n\npython-version:  3.7</code></pre></div>\n<p>This action setup the python version version to use for our application. </p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">-  name:  Set up QEMU\n\nuses:  docker/setup-qemu-action@v1\n\n# https://github.com/docker/setup-buildx-action\n\n-  name:  Set up Docker Buildx\n\nuses:  docker/setup-buildx-action@v1</code></pre></div>\n<p>This one setup the docker bulid tools we will be using .</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">-  name:  create docker cache\n\nuses:  actions/cache@v1\n\nwith:\n\npath:  ${{ github.workspace }}/cache\n\nkey:  ${{ runner.os }}-docker-${{ hashfiles(&#39;cache/**&#39;) }}\n\nrestore-keys:  |\n\n${{ runner.os }}-docker-</code></pre></div>\n<p>This one create the cache we will be using in the build phase.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">-  name:  generating the config files\n\nrun:  |\n\necho &#39;&#39;&#39;${{ secrets.CONFIGURATION_FILE }}&#39;&#39;&#39; &gt;&gt; .env\n\necho &quot;done creating the configuration file&quot;</code></pre></div>\n<p>This one generate our configuration file, so basically if you have enviroment variables in a .env file, this actions will generate them back. </p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">-  name:  Configure AWS credentials\n\nuses:  aws-actions/configure-aws-credentials@v1\n\nwith:\n\naws-access-key-id:  ${{ secrets.AWS_ACCESS_KEY_ID }}\n\naws-secret-access-key:  ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n\naws-region:  us-east-2</code></pre></div>\n<p>As the name stated this actions will configure your aws crendentials so that you can easily login to the ECR. Don’t forget to add your credentials to your github repository secrets</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">-  name:  Login to Amazon ECR\n\nid:  login-ecr\n\nuses:  aws-actions/amazon-ecr-login@v1</code></pre></div>\n<p>As the name stated this use the credentials setup  in the previous steg to login to the container registry.</p>\n<p>Once we are login we can now build the container and push to the container registry . </p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">-  name:  Build, tag, and push image to Amazon ECR\n\nid:  build-image\n\nenv:\n\nECR_REGISTRY:  ${{ steps.login-ecr.outputs.registry }}\n\nECR_REPOSITORY:  ecs-devops-repository\n\nIMAGE_TAG:  ${{ github.sha }}\n\nrun:  |\n\ndocker buildx build -f Dockerfile --cache-from &quot;type=local,src=$GITHUB_WORKSPACE/cache&quot; --cache-to &quot;type=local,dest=$GITHUB_WORKSPACE/cache&quot; --output &quot;type=image, name=$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG,push=true&quot; .\n\necho &quot;::set-output name=image::$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG&quot;</code></pre></div>\n<p>This build the container and push the container registry. Note that the output of this step is the image uri or image name . we will need it in the next step. </p>\n<p>The next step we will fill the image name in the each container definition in our task-definition file , so that the docker container will be pulling the new build docker image.</p>\n<p>There are 3 setps that are in sequence . The output of one step is used in the next step. </p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">-  name:  Fill in the new image ID in the Amazon ECS task definition of the beat container\n\nid:  render-beat-container\n\nuses:  aws-actions/amazon-ecs-render-task-definition@v1\n\nwith:\n\ntask-definition:  ./.aws/task-definition.json\n\ncontainer-name:  celery-beat\n\nimage:  ${{ steps.build-image.outputs.image }}\n\n  \n\n-  name:  Fill in the new image ID in the Amazon ECS task definition of the flower container\n\nid:  render-flower-container\n\nuses:  aws-actions/amazon-ecs-render-task-definition@v1\n\nwith:\n\ntask-definition:  ${{ steps.render-beat-container.outputs.task-definition }}\n\ncontainer-name:  flower\n\nimage:  ${{ steps.build-image.outputs.image }}\n\n  \n\n-  name:  Fill in the new image ID in the Amazon ECS task definition of the worker container\n\nid:  render-worker-container\n\nuses:  aws-actions/amazon-ecs-render-task-definition@v1\n\nwith:\n\ntask-definition:  ${{ steps.render-flower-container.outputs.task-definition }}\n\ncontainer-name:  celery-worker\n\nimage:  ${{ steps.build-image.outputs.image }}</code></pre></div>\n<p>With the task definition updated we can now push the task definitions to the service and start running the service. </p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">-  name:  Deploy Amazon ECS task definition\n\nuses:  aws-actions/amazon-ecs-deploy-task-definition@v1\n\nwith:\n\ntask-definition:  ${{ steps.render-worker-container.outputs.task-definition }}\n\nservice:  ecs-devops-service\n\ncluster:  ecs-devops-cluster\n\nwait-for-service-stability:  false</code></pre></div>\n<p>This is the step that does the actual deployment, it push the task definitions to the service which start the tasks. </p>\n<p>(put informtion about logging to the service), explaine the wait-for-service-stability argunment. </p>\n<p>Put how to check ifi the application is deployed … </p>\n<p>With this added we can make sure we have the following content in our <code class=\"language-text\">.github/workflows/deploy_aws.yml</code> file . </p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">on:\n\npush:\n\nbranches:\n\n-  master\n\nname:  Deploy to Amazon ECS\n\njobs:\n\ndeploy:\n\nname:  Deploy\n\nruns-on:  ubuntu-latest\n\nsteps:\n\n-  name:  Checkout\n\nuses:  actions/checkout@v1\n\n-  name:  Set up Python python-version\n\nuses:  actions/setup-python@v1\n\nwith:\n\npython-version:  3.7\n\n-  name:  Set up QEMU\n\nuses:  docker/setup-qemu-action@v1\n\n# https://github.com/docker/setup-buildx-action\n\n-  name:  Set up Docker Buildx\n\nuses:  docker/setup-buildx-action@v1\n\n-  name:  create docker cache\n\nuses:  actions/cache@v1\n\nwith:\n\npath:  ${{ github.workspace }}/cache\n\nkey:  ${{ runner.os }}-docker-${{ hashfiles(&#39;cache/**&#39;) }}\n\nrestore-keys:  |\n\n${{ runner.os }}-docker-\n\n-  name:  generating the config files\n\nrun:  |\n\necho &#39;&#39;&#39;${{ secrets.CONFIGURATION_FILE }}&#39;&#39;&#39; &gt;&gt; .env\n\necho &quot;done creating the configuration file&quot;\n\n-  name:  Configure AWS credentials\n\nuses:  ws-actions/configure-aws-credentials@v1\n\nwith:\n\naws-access-key-id:  ${{ secrets.AWS_ACCESS_KEY_ID }}\n\naws-secret-access-key:  ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n\naws-region:  us-east-2\n\n-  name:  Login to Amazon ECR\n\nid:  login-ecr\n\nuses:  aws-actions/amazon-ecr-login@v1\n\n  \n\n-  name:  Build, tag, and push image to Amazon ECR\n\nid:  build-image\n\nenv:\n\nECR_REGISTRY:  ${{ steps.login-ecr.outputs.registry }}\n\nECR_REPOSITORY:  ecs-devops-repository\n\nIMAGE_TAG:  ${{ github.sha }}\n\nrun:  |\n\ndocker buildx build -f Dockerfile --cache-from &quot;type=local,src=$GITHUB_WORKSPACE/cache&quot; --cache-to &quot;type=local,dest=$GITHUB_WORKSPACE/cache&quot; --output &quot;type=image, name=$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG,push=true&quot; .\n\necho &quot;::set-output name=image::$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG&quot;\n\n-  name:  Fill in the new image ID in the Amazon ECS task definition of the beat container\n\nid:  render-beat-container\n\nuses:  aws-actions/amazon-ecs-render-task-definition@v1\n\nwith:\n\ntask-definition:  ./.aws/task-definition.json\n\ncontainer-name:  celery-beat\n\nimage:  ${{ steps.build-image.outputs.image }}\n\n-  name:  Fill in the new image ID in the Amazon ECS task definition of the flower container\n\nid:  render-flower-container\n\nuses:  aws-actions/amazon-ecs-render-task-definition@v1\n\nwith:\n\ntask-definition:  ${{ steps.render-beat-container.outputs.task-definition }}\n\ncontainer-name:  flower\n\nimage:  ${{ steps.build-image.outputs.image }}\n\n-  name:  Fill in the new image ID in the Amazon ECS task definition of the worker container\n\nid:  render-worker-container\n\nuses:  aws-actions/amazon-ecs-render-task-definition@v1\n\nwith:\n\ntask-definition:  ${{ steps.render-flower-container.outputs.task-definition }}\n\ncontainer-name:  celery-worker\n\nimage:  ${{ steps.build-image.outputs.image }}\n\n  \n\n-  name:  Deploy Amazon ECS task definition\n\nuses:  aws-actions/amazon-ecs-deploy-task-definition@v1\n\nwith:\n\ntask-definition:  ${{ steps.render-worker-container.outputs.task-definition }}\n\nservice:  ecs-devops-service\n\ncluster:  ecs-devops-cluster\n\nwait-for-service-stability:  false</code></pre></div>\n<p>With that , we can now commit the code and see how the application will start the pipeline and get deployed to AWS.\nRun the following to deploy.</p>\n<p><code class=\"language-text\">git commit -am &#39;setup the ci cd pipeline&#39;</code> </p>\n<p><code class=\"language-text\">git push origin master</code></p>\n<p>We can check if our github actions are running</p>\n<p>(put a screenshot)</p>\n<p>If everything goes well you can visualize the deployement here</p>\n<p><a href=\"https://us-east-2.console.aws.amazon.com/ecs/v2/clusters/ecs-devops-cluster/services/ecs-devops-service/deployments?region=us-east-2\">https://us-east-2.console.aws.amazon.com/ecs/v2/clusters/ecs-devops-cluster/services/ecs-devops-service/deployments?region=us-east-2</a></p>\n<p>Please change your service and cluster with your cluster name and service name in the url. </p>\n<p>If everything in your deployment goes well you can check the logs for your worker to see what is happenning there</p>\n<p><a href=\"https://us-east-2.console.aws.amazon.com/cloudwatch/home?region=us-east-2#logsV2:log-groups/log-group/ecs-devops-service-logs\">https://us-east-2.console.aws.amazon.com/cloudwatch/home?region=us-east-2#logsV2:log-groups/log-group/ecs-devops-service-logs</a></p>","frontmatter":{"title":"Deploy a containerized python to AWS using Github Actions","date":"26 February, 2021","description":"Tutorial on how to build a ci/cd that use github actions to deploy a python to aws."}}},"pageContext":{"isCreatedByStatefulCreatePages":false,"slug":"/ci-cd-deploy-to-aws-github-actions/","previous":{"fields":{"slug":"/ielts-how-it-went/"},"frontmatter":{"title":"I sat for the IELTS today , here is how it went"}},"next":null}}}