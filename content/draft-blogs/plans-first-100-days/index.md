---
title: Plan for the first 100 days of 2020
date: "2020-02-14T22:12:03.284Z"
description: "Thing I need to get done"
---

I hate new year resolution , instead I go with 100 days sprints.

This list contains things I need to get done before end of the first hundred days of this year.

I started the sprint on february 1st 2020 , and I will check up on it end of April where I am.

Things I need to get done In the first 100 days of 2020

- [ ] Completed and deploy and end to end personal project
- [ ] Start and Learn Recurrent Neural Network from Scratch
- [ ] Use  it in an End to End Project (Predicting Blog post Tags)
- [ ] Write 3 blogs post 
- [ ] Learning about recommendations systems and write a blog post 
- [ ] Organize a hackathons for all Congolese leaving in Kigali
- [ ] Put 3 baselines models for Congolese languages on masakhane
- [x] Finish one blog
- [ ] migrate the old blog to the new one and set up google analytic ans SEO
- [ ] Complete the 2 course of Algorithms and Data Structure from Coursera


Talk I need to attend to this year :

PyCon Africa
Data Science Africa
Deep learning Indaba
NeurIps... Only if I finished the deep learning project on time


I have 2 free days in a week, One should be algorithms and Data Structure and Another one for another one for Data Science And NLP


Another 3 days will be concentrated to work !

And weekend will be to catch up with what I didn't completed


Day 1 of Reccurent Neural Network :

Materials so hard from fast.ai , a lot abstraction , Did I miss the basics or ?
Is their approach which is not good for me? Or the because their code is not pythonic? may be

Let me try dl2.ai course and check how it will goes

The book looks great but it could be better to combine both on next time

Or combine it with MIT deep learning 

https://www.youtube.com/watch?v=njKP3FqW3Sk&list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI

Another resources

Day One of DS and Algorithm with Java::

Everything went well get understand the first 45 minutes

Will resume tomorrow :

Keep it up...

Day 2 of recurrent neural network everything went smoothly, I watched the video about RNN 
Got the intuition , read the book, got some intuition but got stuck on the data preparation part , that is where I will start on Monday

Tomorrow I will resume with DS and Algorithms

Day 2 DS and Algorithms Union Find Algorithm Implementation

Things are not going to the peace I want but a least I found useful resources to use .

Day 3 of RNN at least some progress where made:
I learned about word embedding and preprocessing text and how we do world representation.
I didn't get everything at 100 % but I made some progress.


Day 3 of DS and algorithm :

One good step in the right direction but things are not moving fast.

I found one video, went on implementing it and things seems to go well

https://www.youtube.com/watch?v=Gz-K8HLkzeM

Day 4 of RNN:

Another good progress was made, I manage to understand the shape of the input and the output
next is to check how we load data and the random sampling thing and perplexity


Day 4 of Ds and Algorithm

I am failing on this java thing and it's taking me so much time to work with java, learning..
Should I give up???

Day 5 : The goal is to prepare the text RNN
Follow the tutorial and understand almost everything about text processing
it goes well, done with the tutorial, finally I managed to prepare data for training a simple RNN , the word embedding stuff still confusing me...

But I will do something...

Day 6 of RNN :

Today , it was not like yesterday, I found myself lost and not training my neural network, I need more info and to make this done.. at least I should make the forward pass.

Failure at 3 Pm : spend a lot time without understanding the input

Need to come back

Day 7 of RNN:

Thing start getting clear and understood the input shapes except one thing, why the hidden state need to have where comes the dimension of the hiden state?

https://medium.com/towards-artificial-intelligence/whirlwind-tour-of-rnns-a11effb7808f


Day 8 : I review cross entropy function and learn how to apply it .
The main question was how to apply it for RNN what is the correct class label at a given time step

Day 9 : The light about the correct label at each step comes now I am able to continue, let us get blocked again into BPTT
BPTT the intuition was well understood via a good video and I understand the problem of vanishing gradient and exploding gradient.
The next step is to implement BPTT

Day 10 : Implementing BPTT from scratch: Ehhehheehe again other problem will start 
should I thing I should start from implementing backward propagation and then move to BPTT 
Let take the Coming 2 days to implement Backward propagation using ANN
Then I will get back to LSTM

Day 11 RNN : Implementing Forward propagation for ANN and architecture, got bored at the moment when I should calculate the backward propagation for RNN, I will get back to this later tomorrow.

DAY 12 RNN : Backward propagation , what is wrong with this? is it the code or me trying to learn...

Should I get back to the basics or ?

Day 13 RNN : Went back to the basics, read [this chapter](http://neuralnetworksanddeeplearning.com/chap2.html) and things start getting clear, 
I think I have enough information to compelete coding bp from scratch
Today the intutinion comes an I manage to develop a good intution, tommorow I will check other approach and plot results with graphs

Day 14 RNN : Train the model, but the accuracy is increasing instead of decreasing, need to learn more about his
it's decreasing but not in the right way...

Day 15 RNN : Lost track but let me get back today.

Day 16 RNN: Back to the code...
The previous implementation was not wrong at all, it gives me an intuition on how backward propagation works in details now, I need to go back to RNN to discover things by myself.
I will have to write it with pen and paper and implement it.

Day 17 : What did I do, I seems to understand the equation of BPTT now tomorow I will try to implement it with code

Day 18 : Went back to the math of BPTT and learn something but distractions was to many today, I didn't finished what I started !

Day 19 : Math equations drive me crazy end up opening almost 10 taps, end up in a wrong tutorials not explaining the things in a right way.

Will come back tommorow , let me take a break

https://kharshit.github.io/blog/2019/02/22/backpropagation-through-time

And this

https://github.com/go2carter/nn-learn/blob/master/grad-deriv-tex/rnn-grad-deriv.pdf
